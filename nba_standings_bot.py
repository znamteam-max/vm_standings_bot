import os
import sys
import json
import math
import datetime as dt
from zoneinfo import ZoneInfo
from html import escape
from typing import Dict, List, Tuple, Optional

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# ====== Telegram ======
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID")

TZ = ZoneInfo("Europe/Helsinki")  # —Ç–≤–æ–π —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å
USER_AGENT = "NBA-Standings-Bot/1.0 (+https://espn.com, +https://basketball-reference.com)"

# ====== HTTP —Å —Ä–µ—Ç—Ä–∞—è–º–∏ ======
def make_session() -> requests.Session:
    s = requests.Session()
    retries = Retry(
        total=6, connect=6, read=6, backoff_factor=0.7,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"], raise_on_status=False
    )
    s.mount("https://", HTTPAdapter(max_retries=retries))
    s.headers.update({"User-Agent": USER_AGENT})
    return s

SESSION = make_session()

# ====== –£—Ç–∏–ª–∏—Ç—ã ======
def season_end_year(today: dt.date) -> int:
    """
    NBA —Å–µ–∑–æ–Ω –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç—Å—è –≥–æ–¥–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.
    –ï—Å–ª–∏ –º–µ—Å—è—Ü >= 8 (–∞–≤–≥—É—Å—Ç) ‚Äî —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —Å–µ–∑–æ–Ω –Ω–æ–≤–æ–≥–æ –≥–æ–¥–∞ (–æ–∫—Ç—è–±—Ä—å —Å—Ç–∞—Ä—Ç),
    –∏–Ω–∞—á–µ ‚Äî –ø—Ä–æ—à–ª–æ–≥–æ–¥–Ω–∏–π —Å–µ–∑–æ–Ω.
    """
    return today.year + 1 if today.month >= 8 else today.year

def norm_team_key(name: str) -> str:
    """–ü—Ä–∏–≤–æ–¥–∏–º –∏–º—è –∫ –∫–ª—é—á—É –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –º–µ–∂–¥—É —Å–∞–π—Ç–∞–º–∏."""
    return "".join(ch for ch in name.lower() if ch.isalnum())

def pct(w: int, l: int) -> float:
    g = w + l
    return (w / g) if g > 0 else 0.0

def arrow(delta_places: Optional[int]) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–µ–ª–∫—É —Ç—Ä–µ–Ω–¥–∞ –¥–ª—è –º–µ—Å—Ç–∞:
      >0  -> üü¢‚ñ≤+N
      <0  -> üî¥‚ñºN
      ==0 -> ‚ö™Ô∏é=
      None -> ‚ö™Ô∏é=
    """
    if delta_places is None:
        return "‚ö™Ô∏é="
    if delta_places > 0:
        return f"üü¢‚ñ≤+{delta_places}"
    if delta_places < 0:
        return f"üî¥‚ñº{abs(delta_places)}"
    return "‚ö™Ô∏é="

# ====== –ü–∞—Ä—Å–∏–º ESPN (—Ç–µ–∫—É—â–∏–µ standings) ======
def fetch_espn_standings_html() -> Dict[str, List[Dict]]:
    """
    –ü–∞—Ä—Å–∏—Ç https://www.espn.com/nba/standings (–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å:
      {
        "east": [ { "team": "...", "abbr": "...", "w": int, "l": int, "pct": float }, ... ],
        "west": [ ... ]
      }
    """
    url = "https://www.espn.com/nba/standings"
    r = SESSION.get(url, timeout=30)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    # –ù–∞–π–¥—ë–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ "Eastern Conference" –∏ "Western Conference"
    # –∏ –±–ª–∏–∂–∞–π—à–∏–µ –ø–æ—Å–ª–µ –Ω–∏—Ö —Ç–∞–±–ª–∏—Ü—ã
    def parse_conference(title_text: str) -> List[Dict]:
        header = soup.find(lambda tag: tag.name in ("h2", "h3") and title_text in tag.get_text(strip=True))
        if not header:
            # fallback: –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É
            header = soup.find(string=lambda t: t and title_text in t)
            header = header.parent if header else None
        if not header:
            return []
        table = header.find_next("table")
        if not table:
            return []

        # –æ–ø—Ä–µ–¥–µ–ª–∏–º –∏–Ω–¥–µ–∫—Å—ã —Å—Ç–æ–ª–±—Ü–æ–≤ W, L, PCT –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
        thead = table.find("thead")
        tbody = table.find("tbody")
        if not thead or not tbody:
            return []

        ths = [th.get_text(strip=True).upper() for th in thead.find_all("th")]
        # –∏–Ω–æ–≥–¥–∞ ESPN –¥—É–±–ª–∏—Ä—É–µ—Ç "TEAM" –ª–µ–≤–æ/–ø—Ä–∞–≤–æ; –Ω–∞–º –Ω—É–∂–Ω—ã W, L, PCT
        try:
            w_idx = ths.index("W")
            l_idx = ths.index("L")
        except ValueError:
            # –∏–Ω–æ–≥–¥–∞ —à–∞–ø–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–æ—Å—Ç–∞–≤–Ω–æ–π; –ø–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
            w_idx = next((i for i, t in enumerate(ths) if t.startswith("W")), None)
            l_idx = next((i for i, t in enumerate(ths) if t.startswith("L")), None)
        try:
            pct_idx = ths.index("PCT")
        except ValueError:
            pct_idx = next((i for i, t in enumerate(ths) if "PCT" in t), None)

        rows_out = []
        for tr in tbody.find_all("tr"):
            tds = tr.find_all("td")
            if len(tds) < max( (w_idx or 0), (l_idx or 0), (pct_idx or 0) ) + 1:
                continue

            # –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã ‚Äî –±–µ—Ä—ë–º —Ç–µ–∫—Å—Ç –ø–µ—Ä–≤–æ–π —è—á–µ–π–∫–∏, –≤ –Ω–µ–π –µ—Å—Ç—å <a> —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º
            team_cell = tds[0]
            team_a = team_cell.find("a")
            team_name = team_a.get_text(strip=True) if team_a else team_cell.get_text(strip=True)
            abbr_span = team_cell.find("abbr")
            team_abbr = abbr_span.get_text(strip=True) if abbr_span else ""

            def safe_int(x):
                try:
                    return int(str(x).strip())
                except Exception:
                    return 0

            w = safe_int(tds[w_idx].get_text()) if w_idx is not None else 0
            l = safe_int(tds[l_idx].get_text()) if l_idx is not None else 0

            if pct_idx is not None:
                try:
                    pct_val = float(tds[pct_idx].get_text().strip())
                except Exception:
                    pct_val = pct(w, l)
            else:
                pct_val = pct(w, l)

            rows_out.append({
                "team": team_name,
                "abbr": team_abbr,
                "w": w,
                "l": l,
                "pct": pct_val
            })

        # –†–∞–Ω–≥ –ø–æ –ø–æ—Ä—è–¥–∫—É —Å—Ç—Ä–æ–∫
        # –û—Ç—Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ pct, –∑–∞—Ç–µ–º –ø–æ –ø–æ–±–µ–¥–∞–º (–Ω–∞ —Å–ª—É—á–∞–π –ø–ª–æ—Ö–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞)
        rows_out.sort(key=lambda x: (-x["pct"], -x["w"]))
        return rows_out

    east = parse_conference("Eastern Conference")
    west = parse_conference("Western Conference")
    return {"east": east, "west": west}

# ====== –í—á–µ—Ä–∞—à–Ω–∏–µ –º–µ—Å—Ç–∞ (Basketball-Reference) ======
def fetch_bbr_positions_yesterday(today: dt.date) -> Dict[str, Dict[str, int]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–∑–∏—Ü–∏—è–º–∏ –∫–æ–º–∞–Ω–¥ –Ω–∞ –≤—á–µ—Ä–∞:
      { "east": { team_key: rank, ... }, "west": { ... } }
    –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É-–∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –ø–æ –¥–∞—Ç–µ:
      https://www.basketball-reference.com/friv/standings.fcgi?month=MM&day=DD&year=YYYY
    –ï—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞/–ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã ‚Äî –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏.
    """
    yday = today - dt.timedelta(days=1)
    url = f"https://www.basketball-reference.com/friv/standings.fcgi?month={yday.month}&day={yday.day}&year={yday.year}"
    try:
        r = SESSION.get(url, timeout=30)
        if r.status_code != 200 or not r.text:
            return {"east": {}, "west": {}}
        soup = BeautifulSoup(r.text, "html.parser")

        # –ò—â–µ–º –±–ª–æ–∫–∏ —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ "Eastern Conference" / "Western Conference" –∏ –±–ª–∏–∂–∞–π—à–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        def extract_positions(title_text: str) -> Dict[str, int]:
            header = soup.find(lambda tag: tag.name in ("h2", "h3") and title_text in tag.get_text(strip=True))
            if not header:
                header = soup.find(string=lambda t: t and title_text in t)
                header = header.parent if header else None
            if not header:
                return {}

            table = header.find_next("table")
            if not table:
                return {}

            body = table.find("tbody") or table
            positions = {}
            rank = 1
            for tr in body.find_all("tr"):
                # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ—á–Ω—ã–µ/—Ç–æ—Ç–∞–ª —Å—Ç—Ä–æ–∫–∏
                if tr.get("class") and any(c in ("thead", "stat_total") for c in tr.get("class", [])):
                    continue
                tcell = tr.find("a")
                if not tcell:
                    continue
                team_name = tcell.get_text(strip=True)
                positions[norm_team_key(team_name)] = rank
                rank += 1
            return positions

        east_pos = extract_positions("Eastern Conference")
        west_pos = extract_positions("Western Conference")
        return {"east": east_pos, "west": west_pos}
    except Exception:
        return {"east": {}, "west": {}}

# ====== –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü —Å —Ç—Ä–µ–Ω–¥–æ–º ======
def attach_trend(current_rows: List[Dict], yesterday_positions: Dict[str, int]) -> List[Dict]:
    """
    current_rows: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π {team, abbr, w, l, pct}
    yesterday_positions: —Å–ª–æ–≤–∞—Ä—å team_key -> rank_yd
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ—Ç –∂–µ —Å–ø–∏—Å–æ–∫, –¥–æ–±–∞–≤–ª—è—è:
      - "rank" (—Å–µ–≥–æ–¥–Ω—è)
      - "delta_places" (–≤—á–µ—Ä–∞—à–Ω–∏–π —Ä–∞–Ω–≥ - —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π)
    """
    # —Ä–∞–Ω–∂–∏—Ä—É–µ–º –ø–æ —Ç–µ–∫—É—â–µ–º—É –ø–æ—Ä—è–¥–∫—É
    ranked = sorted(current_rows, key=lambda x: (-x["pct"], -x["w"]))
    for i, row in enumerate(ranked, start=1):
        row["rank"] = i
        key = norm_team_key(row["team"])
        y_rank = yesterday_positions.get(key)
        if y_rank is None:
            row["delta_places"] = None
        else:
            # –µ—Å–ª–∏ –≤—á–µ—Ä–∞ –±—ã–ª 5, —Å–µ–≥–æ–¥–Ω—è 3 ‚Äî delta_places = +2 (–ø–æ–¥–Ω—è–ª–∏—Å—å)
            row["delta_places"] = y_rank - i
    return ranked

def fmt_table(title: str, rows: List[Dict]) -> str:
    """
    –§–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏ —Å —Ç–∞–±–ª–∏—Ü–µ–π –¥–ª—è Telegram.
    –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫–∏:
      1  üü¢‚ñ≤+2  BOS  5‚Äì1  (83.3%)
    """
    out = [f"<b>{escape(title)}</b>"]
    for r in rows:
        w, l = r["w"], r["l"]
        pct_val = r["pct"]
        arrow_str = arrow(r.get("delta_places"))
        abbr = r["abbr"] if r.get("abbr") else r["team"]
        pct_str = f"{pct_val:.3f}"
        out.append(f"{r['rank']:>2} {arrow_str:>4}  {escape(abbr)}  {w}‚Äì{l}  ({pct_str})")
    return "\n".join(out)

# ====== –°–æ–æ–±—â–µ–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ ======
def build_message() -> str:
    today = dt.datetime.now(tz=TZ).date()
    cur = fetch_espn_standings_html()
    prev = fetch_bbr_positions_yesterday(today)

    east = attach_trend(cur["east"], prev["east"])
    west = attach_trend(cur["west"], prev["west"])

    head = f"<b>–ù–ë–ê ¬∑ –¢–∞–±–ª–∏—Ü–∞ –ø–æ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è–º</b> ‚Äî {today.strftime('%d %b %Y')}"
    info = "‚ÑπÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫–∏: ESPN (—Ç–µ–∫—É—â–∞—è —Ç–∞–±–ª–∏—Ü–∞), Basketball-Reference (–ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –≤—á–µ—Ä–∞)."
    return "\n\n".join([head, fmt_table("–í–æ—Å—Ç–æ—á–Ω–∞—è –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è", east),
                        "", fmt_table("–ó–∞–ø–∞–¥–Ω–∞—è –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è", west),
                        "", info])

def send_telegram(text: str):
    if not (BOT_TOKEN and CHAT_ID):
        print("No TELEGRAM_BOT_TOKEN/CHAT_ID in env", file=sys.stderr)
        return
    r = SESSION.post(
        f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
        json={"chat_id": CHAT_ID, "text": text, "parse_mode": "HTML", "disable_web_page_preview": True},
        timeout=25
    )
    r.raise_for_status()

# ====== main ======
if __name__ == "__main__":
    try:
        msg = build_message()
        send_telegram(msg)
        print("OK")
    except Exception as e:
        print("ERROR:", repr(e), file=sys.stderr)
        sys.exit(1)
